# model.py
# -*- coding: utf-8 -*-
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential, load_model
from keras.layers import Dense, LSTM, Dropout
from keras.utils import plot_model
import os
import math
from sklearn.metrics import mean_squared_error
from server_model.config import DATA_PATH, MODEL_SAVE_PATH, MODEL_PLOT_PATH, MODEL_SHAPES_PLOT_PATH, PREDICTION_PLOT_PATH

# ë°ì´í„° ë¡œë”©
dataset = pd.read_csv(DATA_PATH, index_col='Date', parse_dates=['Date'], encoding='utf-8')

# ë°ì´í„° ì „ì²˜ë¦¬
training_set = dataset.loc[:'2016', ["High"]].values
test_set = dataset.loc['2017':, ["High"]].values

# ìŠ¤ì¼€ì¼ë§
sc = MinMaxScaler(feature_range=(0, 1))
training_set_scaled = sc.fit_transform(training_set)

# LSTM ì…ë ¥ ë°ì´í„° ì¤€ë¹„
X_train, y_train = [], []
for i in range(60, len(training_set)):
    X_train.append(training_set_scaled[i-60:i, 0])
    y_train.append(training_set_scaled[i, 0])
X_train, y_train = np.array(X_train), np.array(y_train)
X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))

# ëª¨ë¸ êµ¬ì¶•
regressor = Sequential([
    LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)),
    Dropout(0.2),
    LSTM(units=50, return_sequences=True),
    Dropout(0.2),
    LSTM(units=50, return_sequences=True),
    Dropout(0.2),
    LSTM(units=50),
    Dropout(0.2),
    Dense(units=1)
])

# ëª¨ë¸ ì»´íŒŒì¼ ë° í•™ìŠµ
regressor.compile(optimizer='rmsprop', loss='mean_squared_error')
regressor.fit(X_train, y_train, epochs=2, batch_size=32)

# ëª¨ë¸ ì €ì¥
regressor.save(MODEL_SAVE_PATH)
print(f"Model saved to '{MODEL_SAVE_PATH}'")

# ëª¨ë¸ êµ¬ì¡° ì´ë¯¸ì§€ ìƒì„±
plot_model(regressor, to_file=MODEL_PLOT_PATH)
plot_model(regressor, to_file=MODEL_SHAPES_PLOT_PATH, show_shapes=True)
print(f"Model structure saved to '{MODEL_PLOT_PATH}' and '{MODEL_SHAPES_PLOT_PATH}'")

# ğŸš€ *ì¶”ê°€ëœ `process()` í•¨ìˆ˜**
def process(dataset):
    """ ì£¼ì–´ì§„ ë°ì´í„°ì…‹ìœ¼ë¡œ ëª¨ë¸ì„ ë¡œë“œí•˜ê³  ì˜ˆì¸¡ì„ ìˆ˜í–‰ """
    model = load_model(MODEL_SAVE_PATH)

    # 'High' ì—´ ì„ íƒ
    training_set = dataset.loc[:'2016', ["High"]].values
    test_set = dataset.loc['2017':, ["High"]].values

    # ë°ì´í„° ìŠ¤ì¼€ì¼ë§
    sc = MinMaxScaler(feature_range=(0, 1))
    training_set_scaled = sc.fit_transform(training_set)

    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
    dataset_total = pd.concat([dataset.loc[:'2016', "High"], dataset.loc['2017':, "High"]], axis=0)
    inputs = dataset_total[len(dataset_total) - len(test_set) - 60:].values
    inputs = inputs.reshape(-1, 1)
    inputs = sc.transform(inputs)

    X_test = []
    for i in range(60, len(inputs)):
        X_test.append(inputs[i-60:i, 0])
    X_test = np.array(X_test)
    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))

    # ëª¨ë¸ ì˜ˆì¸¡
    predicted_stock_price = model.predict(X_test)
    predicted_stock_price = sc.inverse_transform(predicted_stock_price)

    # ê²°ê³¼ ì‹œê°í™” ë° í‰ê°€
    result_visualizing = plot_predictions(test_set, predicted_stock_price)
    result_evaluating = return_rmse(test_set, predicted_stock_price)

    return result_visualizing, result_evaluating

# ğŸš€ ì¶”ê°€ëœ `plot_predictions()` ë° `return_rmse()` í•¨ìˆ˜**
def plot_predictions(test, predicted):
    plt.clf()  # ì´ì „ ê·¸ë˜í”„ ì´ˆê¸°í™”
    plt.plot(test, color='red', label='Real IBM Stock Price')
    plt.plot(predicted, color='blue', label='Predicted IBM Stock Price')
    plt.title('IBM Stock Price Prediction')
    plt.xlabel('Time')
    plt.ylabel('IBM Stock Price')
    plt.legend()
    plt.savefig(PREDICTION_PLOT_PATH)
    return PREDICTION_PLOT_PATH

def return_rmse(test, predicted):
    rmse = math.sqrt(mean_squared_error(test, predicted))
    result_msg = f"The root mean squared error is {rmse}."
    print(result_msg)
    return result_msg
